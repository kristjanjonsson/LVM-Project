{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import time\n",
    "import logging\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "import scipy as sp\n",
    "import os\n",
    "\n",
    "try:\n",
    "    import ujson as json\n",
    "except ImportError:\n",
    "    import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/ml-100k/u1.base', sep='\\t', names=['user', 'movie', 'rating', 'time'], usecols=[0,1,2])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to dense matrix\n",
    "users = data.get_values()[:,0] - 1\n",
    "movies = data.get_values()[:,1] - 1\n",
    "ratings = data.get_values()[:,2]\n",
    "r = csr_matrix((ratings, (users, movies))).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = r[:600, :500]\n",
    "r = r.astype(np.float32)\n",
    "\n",
    "# mark missing values\n",
    "zeros = r == 0\n",
    "r[zeros] = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enable on-the-fly graph computations, but ignore \n",
    "# absence of intermediate test values.\n",
    "theano.config.compute_test_value = 'ignore'\n",
    "\n",
    "# Set up logging.\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "class PMF(object):\n",
    "    \"\"\"Probabilistic Matrix Factorization model using pymc3.\"\"\"\n",
    "\n",
    "    def __init__(self, train, dim, alpha=2, std=0.01, bounds=(-10, 10)):\n",
    "        \"\"\"Build the Probabilistic Matrix Factorization model using pymc3.\n",
    "\n",
    "        :param np.ndarray train: The training data to use for learning the model.\n",
    "        :param int dim: Dimensionality of the model; number of latent factors.\n",
    "        :param int alpha: Fixed precision for the likelihood function.\n",
    "        :param float std: Amount of noise to use for model initialization.\n",
    "        :param (tuple of int) bounds: (lower, upper) bound of ratings.\n",
    "            These bounds will simply be used to cap the estimates produced for R.\n",
    "\n",
    "        \"\"\"\n",
    "        self.dim = dim\n",
    "        self.alpha = alpha\n",
    "        self.std = np.sqrt(1.0 / alpha)\n",
    "        self.bounds = bounds\n",
    "        self.data = train.copy()\n",
    "        n, m = self.data.shape\n",
    "\n",
    "        # Perform mean value imputation\n",
    "#         nan_mask = np.isnan(self.data)\n",
    "#         self.data[nan_mask] = self.data[~nan_mask].mean()\n",
    "\n",
    "        # Low precision reflects uncertainty; prevents overfitting.\n",
    "        # Set to the mean variance across users and items.\n",
    "        self.alpha_u = 1 / self.data.var(axis=1).mean()\n",
    "        self.alpha_v = 1 / self.data.var(axis=0).mean()\n",
    "\n",
    "        # Specify the model.\n",
    "        logging.info('building the PMF model')\n",
    "        with pm.Model() as pmf:\n",
    "            U = pm.MvNormal(\n",
    "                'U', mu=0, tau=self.alpha_u * np.eye(dim),\n",
    "                shape=(n, dim), testval=np.random.randn(n, dim) * std)\n",
    "            V = pm.MvNormal(\n",
    "                'V', mu=0, tau=self.alpha_v * np.eye(dim),\n",
    "                shape=(m, dim), testval=np.random.randn(m, dim) * std)\n",
    "            R = pm.Normal(\n",
    "                'R', mu=theano.tensor.dot(U, V.T), tau=self.alpha * np.ones((n, m)),\n",
    "                observed=pd.DataFrame(self.data))\n",
    "\n",
    "        logging.info('done building the PMF model') \n",
    "        self.model = pmf\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First define functions to save our MAP estimate after it is found.\n",
    "# We adapt these from `pymc3`'s `backends` module, where the original\n",
    "# code is used to save the traces from MCMC samples.\n",
    "def save_np_vars(vars, savedir):\n",
    "    \"\"\"Save a dictionary of numpy variables to `savedir`. We assume\n",
    "    the directory does not exist; an OSError will be raised if it does.\n",
    "    \"\"\"\n",
    "    logging.info('writing numpy vars to directory: %s' % savedir)\n",
    "    os.mkdir(savedir)\n",
    "    shapes = {}\n",
    "    for varname in vars:\n",
    "        data = vars[varname]\n",
    "        var_file = os.path.join(savedir, varname + '.txt')\n",
    "        np.savetxt(var_file, data.reshape(-1, data.size))\n",
    "        shapes[varname] = data.shape\n",
    "\n",
    "        ## Store shape information for reloading.\n",
    "        shape_file = os.path.join(savedir, 'shapes.json')\n",
    "        with open(shape_file, 'w') as sfh:\n",
    "            json.dump(shapes, sfh)\n",
    "\n",
    "\n",
    "def load_np_vars(savedir):\n",
    "    \"\"\"Load numpy variables saved with `save_np_vars`.\"\"\"\n",
    "    shape_file = os.path.join(savedir, 'shapes.json')\n",
    "    with open(shape_file, 'r') as sfh:\n",
    "        shapes = json.load(sfh)\n",
    "\n",
    "    vars = {}\n",
    "    for varname, shape in shapes.items():\n",
    "        var_file = os.path.join(savedir, varname + '.txt')\n",
    "        vars[varname] = np.loadtxt(var_file).reshape(shape)\n",
    "\n",
    "    return vars\n",
    "\n",
    "\n",
    "# Now define the MAP estimation infrastructure.\n",
    "def _map_dir(self):\n",
    "    basename = 'pmf-map-d%d' % self.dim\n",
    "    return os.path.join('data', basename)\n",
    "\n",
    "def _find_map(self):\n",
    "    \"\"\"Find mode of posterior using Powell optimization.\"\"\"\n",
    "    tstart = time.time()\n",
    "    with self.model:\n",
    "        logging.info('finding PMF MAP using Powell optimization...')\n",
    "        self._map = pm.find_MAP(fmin=sp.optimize.fmin_powell)\n",
    "\n",
    "    elapsed = int(time.time() - tstart)\n",
    "    logging.info('found PMF MAP in %d seconds' % elapsed)\n",
    "\n",
    "    # This is going to take a good deal of time to find, so let's save it.\n",
    "    save_np_vars(self._map, self.map_dir)\n",
    "\n",
    "def _load_map(self):\n",
    "    self._map = load_np_vars(self.map_dir)\n",
    "\n",
    "def _map(self):\n",
    "    try:\n",
    "        return self._map\n",
    "    except:\n",
    "        if os.path.isdir(self.map_dir):\n",
    "            self.load_map()\n",
    "        else:\n",
    "            self.find_map()\n",
    "        return self._map\n",
    "\n",
    "\n",
    "# Update our class with the new MAP infrastructure.\n",
    "PMF.find_map = _find_map\n",
    "PMF.load_map = _load_map\n",
    "PMF.map_dir = property(_map_dir)\n",
    "PMF.map = property(_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw MCMC samples.\n",
    "def _trace_dir(self):\n",
    "    basename = 'pmf-mcmc-d%d' % self.dim\n",
    "    return os.path.join('data', basename)\n",
    "\n",
    "def _draw_samples(self, nsamples=1000, njobs=2):\n",
    "    # First make sure the trace_dir does not already exist.\n",
    "    if os.path.isdir(self.trace_dir):\n",
    "        raise OSError(\n",
    "            'trace directory %s already exists. Please move or delete.' % self.trace_dir)\n",
    "    start = self.map  # use our MAP as the starting point\n",
    "    with self.model:\n",
    "        logging.info('drawing %d samples using %d jobs' % (nsamples, njobs))\n",
    "        step = pm.NUTS(scaling=start)\n",
    "        backend = pm.backends.Text(self.trace_dir)\n",
    "        logging.info('backing up trace to directory: %s' % self.trace_dir)\n",
    "        self.trace = pm.sample(nsamples, step, start=start, njobs=njobs, trace=backend)\n",
    "\n",
    "def _load_trace(self):\n",
    "    with self.model:\n",
    "        self.trace = pm.backends.text.load(self.trace_dir)\n",
    "\n",
    "\n",
    "# Update our class with the sampling infrastructure.\n",
    "PMF.trace_dir = property(_trace_dir)\n",
    "PMF.draw_samples = _draw_samples\n",
    "PMF.load_trace = _load_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _predict(self, U, V):\n",
    "    \"\"\"Estimate R from the given values of U and V.\"\"\"\n",
    "    R = np.dot(U, V.T)\n",
    "    n, m = R.shape\n",
    "    sample_R = np.array([\n",
    "        [np.random.normal(R[i,j], self.std) for j in range(m)]\n",
    "        for i in range(n)\n",
    "    ])\n",
    "\n",
    "    # bound ratings\n",
    "    low, high = self.bounds\n",
    "    sample_R[sample_R < low] = low\n",
    "    sample_R[sample_R > high] = high\n",
    "    return sample_R\n",
    "\n",
    "\n",
    "PMF.predict = _predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define our evaluation function.\n",
    "def rmse(test_data, predicted):\n",
    "    \"\"\"Calculate root mean squared error.\n",
    "    Ignoring missing values in the test data.\n",
    "    \"\"\"\n",
    "    I = ~np.isnan(test_data)   # indicator for missing values\n",
    "    N = I.sum()                # number of non-missing values\n",
    "    sqerror = abs(test_data - predicted) ** 2  # squared error array\n",
    "    mse = sqerror[I].sum() / N                 # mean squared error\n",
    "    return np.sqrt(mse)                        # RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We use a fixed precision for the likelihood.\n",
    "# This reflects uncertainty in the dot product.\n",
    "# We choose 2 in the footsteps Salakhutdinov\n",
    "# Mnihof.\n",
    "ALPHA = 2\n",
    "\n",
    "# The dimensionality D; the number of latent factors.\n",
    "# We can adjust this higher to try to capture more subtle\n",
    "# characteristics of each joke. However, the higher it is,\n",
    "# the more expensive our inference procedures will be.\n",
    "# Specifically, we have D(N + M) latent variables. For our\n",
    "# Jester dataset, this means we have D(1100), so for 5\n",
    "# dimensions, we are sampling 5500 latent variables.\n",
    "DIM = 5\n",
    "\n",
    "\n",
    "pmf = PMF(r, DIM, ALPHA, std=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pmf.find_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval_map(pmf_model, train, test):\n",
    "    U = pmf_model.map['U']\n",
    "    V = pmf_model.map['V']\n",
    "\n",
    "    # Make predictions and calculate RMSE on train & test sets.\n",
    "    predictions = pmf_model.predict(U, V)\n",
    "    train_rmse = rmse(train, predictions)\n",
    "    test_rmse = rmse(test, predictions)\n",
    "    overfit = test_rmse - train_rmse\n",
    "\n",
    "    # Print report.\n",
    "    print('PMF MAP training RMSE: %.5f' % train_rmse)\n",
    "    print('PMF MAP testing RMSE:  %.5f' % test_rmse)\n",
    "    print('Train/test difference: %.5f' % overfit)\n",
    "\n",
    "    return test_rmse\n",
    "\n",
    "\n",
    "# Add eval function to PMF class.\n",
    "PMF.eval_map = eval_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate PMF MAP estimates.\n",
    "pmf_map_rmse = pmf.eval_map(r, r)\n",
    "pmf_improvement = baselines['mom'] - pmf_map_rmse\n",
    "print('PMF MAP Improvement:   %.5f' % pmf_improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
